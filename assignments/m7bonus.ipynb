{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M7 Bonus \n",
    "#### Training a Convolutional Neural Net on the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# configuring machine to utilize GPU with cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# loading cifar-10 training and testing with transforming it\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# loading cifar-10 training data\n",
    "cifar10_training_data = datasets.CIFAR10(\n",
    "    './data/cifar10', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# loading cifar-10 test data\n",
    "cifar10_testing_data = datasets.CIFAR10(\n",
    "    './data/cifar10', \n",
    "    train=False, \n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining cnn model\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    \"\"\"    \n",
    "    Convolutional Neural Network for classifying CIFAR-10 dataset.\n",
    "\n",
    "    Attributes:\n",
    "        convolution_layer (nn.Sequential): A sequential container of convolutional layers\n",
    "            that includes convolution, batch normalization, ReLU activations, and pooling.\n",
    "        fullyconnected_layer (nn.Sequential): A sequential container of fully connected\n",
    "            layers with dropout for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolution_layer = nn.Sequential(\n",
    "            # first block : (input: 3 channels, output: 32 channels)\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # second block : (input: 64 channels, output: 128 channels)\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # third block : (input: 128 channels, output: 256 channels)\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fullyconnected_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),  # (input: 4096 features, output: 1024 features)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),   # (input: 1024 features, output: 512 features)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)  # final layer (input: 512 features, output: 10 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolution\n",
    "        x = self.convolution_layer(x)\n",
    "\n",
    "        # flatten view\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # fully connected layer\n",
    "        x = self.fullyconnected_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# model = ConvNeuralNet()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def training(model, train_dataloader, optimizer, criterion, epoch, device, print_freq=10):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for batch_idx, (data, labels) in enumerate(train_dataloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # propagation\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print stats\n",
    "        training_loss += loss.item() * data.shape[0]\n",
    "\n",
    "\n",
    "        if not (batch_idx % print_freq):\n",
    "            print(f\"Batch: {batch_idx}/{len(train_dataloader)} | \", \n",
    "                  f\"Training Loss: {loss.item():.4f} | \"\n",
    "            )\n",
    "    return training_loss / len(train_dataloader.dataset)\n",
    "\n",
    "# testing function\n",
    "def testing(model, test_dataloader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            # move data and target to the specified device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # forward pass \n",
    "            output = model(data)\n",
    "\n",
    "            # calculate loss\n",
    "            test_loss += criterion(output, target).item() * data.size(0)\n",
    "\n",
    "            # get predictions\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    # average loss\n",
    "    average_loss = test_loss / total\n",
    "    # calculate accuracy\n",
    "    accuracy = correct / total * 100\n",
    "\n",
    "    print(f'Test Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, train_dataloader, test_dataloader, optimizer, criterion, num_epochs, device):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # train the model\n",
    "        train_loss = training(model, train_dataloader, optimizer, criterion, epoch, device)\n",
    "\n",
    "    # test the model\n",
    "    test_loss, test_accuracy = testing(model, test_dataloader, criterion, device)\n",
    "\n",
    "    return train_loss, test_loss, test_accuracy\n",
    "\n",
    "\n",
    "# init params\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "# init model\n",
    "model = ConvNeuralNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# load cifar-10 dataloaders\n",
    "\n",
    "# trainloader\n",
    "cifar_trainloader = DataLoader(\n",
    "    cifar10_training_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# testloader\n",
    "cifar_testloader = DataLoader(\n",
    "    cifar10_testing_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# init model, optimizer, criterion\n",
    "model = ConvNeuralNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# call train_test\n",
    "train_loss, test_loss, test_accuracy = train_test(\n",
    "    model, \n",
    "    cifar_trainloader, \n",
    "    cifar_testloader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    epochs, \n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"Final Training Loss: {train_loss:.4f}, Final Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without re-implementing ResNet architectures and data augmentations:\n",
    "\n",
    "Run 1 Results:<br>\n",
    "(batch size = 64)<br>\n",
    "Final Training Loss: 0.2981, Final Test Loss: 0.6369, Test Accuracy: 80.62%\n",
    "\n",
    "Run 2 Results:<br>\n",
    "(batch size = 64)<br>\n",
    "Final Training Loss: 0.3409, Final Test Loss: 0.5919, Test Accuracy: 81.60%\n",
    "\n",
    "Run 3 Results:<br>\n",
    "(batch size = 128)<br>\n",
    "Final Training Loss: 0.2351, Final Test Loss: 0.6708, Test Accuracy: 81.02%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
